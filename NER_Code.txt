# -*- coding: utf-8 -*-
"""NER_dwamjar.txt

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12kSGc6fvD4usUXVtTEXviF_ofb_Q_aRO

# Step 1: Load the Excel File
"""

import pandas as pd
import re
import requests
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Set file paths (Modify these paths as needed)
dictionary_path = "/content/drive/MyDrive/proces_data/Kurdish_NER_Dictionary.xlsx"

# Load the dictionary (Excel file)
dictionary_df = pd.read_excel(dictionary_path)
dictionary_words = set(dictionary_df["name"].astype(str).str.strip())

dictionary_df

dictionary_df.loc[dictionary_df['categories']=='Person','categories'] = 'Persons'
dictionary_df.loc[dictionary_df['categories'] == 'person', 'categories'] = 'Persons'
dictionary_df.loc[dictionary_df['categories']=='organization','categories'] = 'Organization'

per_data = dictionary_df[dictionary_df['categories']=='Persons']
loc_data = dictionary_df[dictionary_df['categories']=='Locations']
sport_data = dictionary_df[dictionary_df['categories']=='Sport']
country_data = dictionary_df[dictionary_df['categories']=='Country']
per_currency = dictionary_df[dictionary_df['categories']=='Currency']
org_data = dictionary_df[dictionary_df['categories']=='Organization']
pos_data = dictionary_df[dictionary_df['categories']=='Positon']
month_data = dictionary_df[dictionary_df['categories']=='Month']
misc_data = dictionary_df[dictionary_df['categories']=='MISC']
pp_data = dictionary_df[dictionary_df['categories']=='Political_Party']
day_data = dictionary_df[dictionary_df['categories']=='Days']
religion_data = dictionary_df[dictionary_df['categories']=='Religion']
season_data = dictionary_df[dictionary_df['categories']=='Season']
eqeument_data = dictionary_df[dictionary_df['categories']=='eqeument']
event_data = dictionary_df[dictionary_df['categories']=='event']

dictionary_df['categories'].value_counts()

dictionary_df['categories'].value_counts().plot(kind='bar')

dictionary_df['categories'].value_counts().plot(kind='pie')

# Fetch prefixes and suffixes from the API
def fetch_api_data(api_url, key):
    try:
        response = requests.get(api_url)
        if response.status_code == 200:
            json_response = response.json()
            return json_response.get(key, [])
        else:
            print(f"API failed with status code: {response.status_code}")
            return []
    except Exception as e:
        print(f"Error connecting to API: {e}")
        return []

prefixes = fetch_api_data('https://ghaziabdullah.pythonanywhere.com/prefixes', 'prefixes')
suffixes = fetch_api_data('https://ghaziabdullah.pythonanywhere.com/suffixes', 'suffixes')

# Function to remove prefixes and suffixes only if the stripped word is in the dictionary
def remove_prefix_suffix(word, prefixes, suffixes):
    # Skip words that are already in the dictionary
    if word in dictionary_words:
        return word

    # Try removing prefixes
    for prefix in prefixes:
        if word.startswith(prefix):
            stripped = word[len(prefix):]
            if stripped in dictionary_words:
                return stripped  # Only return if stripped version is a known entity

    # Try removing suffixes
    for suffix in suffixes:
        if word.endswith(suffix):
            stripped = word[:-len(suffix)]
            if stripped in dictionary_words:
                return stripped  # Only return if stripped version is a known entity

    return word  # Return original word if no match is found

"""# Step 2: Define the Rule-Based Functions"""

def is_sport(word, sport_data):
    return word in sport_data['name'].values

def is_country(word, country_data):
    return word in country_data['name'].values

def is_currency(word, per_currency):
    return word in per_currency['name'].values

def is_position(word, pos_data):
    return word in pos_data['name'].values

def is_month(word, month_data):
    return word in month_data['name'].values

def is_misc(word, misc_data):
    return word in misc_data['name'].values

def is_political_party(word, pp_data):
    return word in pp_data['name'].values

def is_day(word, day_data):
    return word in day_data['name'].values

def is_religion(word, religion_data):
    return word in religion_data['name'].values

def is_season(word, season_data):
    return word in season_data['name'].values

def is_equipment(word, eqeument_data):
    return word in eqeument_data['name'].values

def is_event(word, event_data):
    return word in event_data['name'].values

import pandas as pd
import re
import requests

def apply_rules_to_text(text, per_data, org_data, loc_data, sport_data, country_data, per_currency, pos_data,
                        month_data, misc_data, pp_data, day_data, religion_data,
                        season_data, eqeument_data, event_data):
    """Applies all rules to the given text and returns a list of tuples."""
    text = re.sub(r'[^\w\s]', '', text)
    tokens = text.split()
    labels = ['O'] * len(tokens)
    length = len(tokens)

    # Check for multi-word entities first
    for i in range(length):
        for j in range(length, i, -1):
            phrase = ' '.join(tokens[i:j])
            cleaned_phrase = remove_prefix_suffix(phrase, prefixes, suffixes)
            if  phrase in per_data['name'].values or cleaned_phrase in per_data['name'].values:
                labels[i:j] = ['B-PER'] + ['I-PER'] * (j - i - 1)
                break
            elif phrase in org_data['name'].values or cleaned_phrase in org_data['name'].values:
                labels[i:j] = ['B-ORG'] + ['I-ORG'] * (j - i - 1)
                break
            elif phrase in loc_data['name'].values or cleaned_phrase in loc_data['name'].values:
                labels[i:j] = ['B-LOC'] + ['I-LOC'] * (j - i - 1)
                break
            elif phrase in sport_data['name'].values or cleaned_phrase in sport_data['name'].values:
                labels[i:j] = ['B-SPORT'] + ['I-SPORT'] * (j - i - 1)
                break
            elif phrase in country_data['name'].values or cleaned_phrase in country_data['name'].values:
              labels[i:j] = ['B-COUNTRY'] + ['I-COUNTRY'] * (j - i -1)
              break
            elif phrase in per_currency['name'].values or cleaned_phrase in per_currency['name'].values:
              labels[i:j] = ['B-CURRENCY'] + ['I-CURRENCY'] * (j - i -1)
              break
            elif phrase in pos_data['name'].values or cleaned_phrase in pos_data['name'].values:
              labels[i:j] = ['B-POSITION'] + ['I-POSITION'] * (j - i -1)
              break
            elif phrase in month_data['name'].values or cleaned_phrase in month_data['name'].values:
              labels[i:j] = ['B-MONTH'] + ['I-MONTH'] * (j - i -1)
              break
            elif phrase in misc_data['name'].values or cleaned_phrase in misc_data['name'].values:
              labels[i:j] = ['B-MISC'] + ['I-MISC'] * (j - i -1)
              break
            elif phrase in pp_data['name'].values or cleaned_phrase in pp_data['name'].values:
              labels[i:j] = ['B-POLITICAL_PARTY'] + ['I-POLITICAL_PARTY'] * (j - i -1)
              break
            elif phrase in day_data['name'].values or cleaned_phrase in day_data['name'].values:
              labels[i:j] = ['B-DAY'] + ['I-DAY'] * (j - i -1)
              break
            elif phrase in religion_data['name'].values or cleaned_phrase in religion_data['name'].values:
              labels[i:j] = ['B-RELIGION'] + ['I-RELIGION'] * (j - i -1)
              break
            elif phrase in season_data['name'].values or cleaned_phrase in season_data['name'].values:
              labels[i:j] = ['B-SEASON'] + ['I-SEASON'] * (j - i -1)
              break
            elif phrase in eqeument_data['name'].values or cleaned_phrase in eqeument_data['name'].values:
              labels[i:j] = ['B-EQUIPMENT'] + ['I-EQUIPMENT'] * (j - i -1)
              break
            elif phrase in event_data['name'].values or cleaned_phrase in event_data['name'].values:
              labels[i:j] = ['B-EVENT'] + ['I-EVENT'] * (j - i -1)
              break


    # Check for consecutive equal labels (B- and I-)
    for i in range(len(labels) - 1):
        if labels[i] != 'O' and labels[i] == labels[i+1]:
            if labels[i].startswith('B-'):
                labels[i+1] = labels[i].replace('B-', 'I-')
        elif i < len(labels) - 2 and labels[i] != 'O' and labels[i] == labels[i+1] and labels[i] == labels[i+2]:
            if labels[i].startswith('B-'):
                labels[i+1] = labels[i].replace('B-', 'I-')
                labels[i+2] = labels[i].replace('B-', 'I-')

    return list(zip(tokens, labels))

"""# Step 3: Apply the Rules to a Text"""

with open('/content/drive/MyDrive/proces_data/Kurdish Corpus_content.txt', 'r') as file:
  data = file.read()
data

corpus = data.split('\n')
corpus

from tqdm import tqdm

with open('labeled_corpus.txt', 'a') as f:
  for text in tqdm(corpus):
    text = re.sub(r'[^\w\s]', '', text)
    tokens = text.split()
    length = len(tokens)
    sentence = []
    labels = []
    annotated_text = apply_rules_to_text(text, per_data, org_data, loc_data, sport_data, country_data, per_currency, pos_data,
                          month_data, misc_data, pp_data, day_data, religion_data,
                          season_data, eqeument_data, event_data)
    for word, label in annotated_text:
      f.write(word + ',' + label)
      f.write('\n')
    f.write('\n')

for text in tqdm(corpus):
  text = re.sub(r'[^\w\s]', '', text)
  tokens = text.split()
  length = len(tokens)
  sentence = []
  labels = []
  annotated_text = apply_rules_to_text(text, per_data, org_data, loc_data, sport_data, country_data, per_currency, pos_data,
                        month_data, misc_data, pp_data, day_data, religion_data,
                        season_data, eqeument_data, event_data)
  for word, label in annotated_text:
    sentence.append(word)
    labels.append(label)
  with open('/content/drive/My Drive/proces_data/Annotated_ADD.txt', 'a') as f:
    for word, label in zip(sentence, labels):
      f.write(word + ' ' + label)
      f.write('\n')